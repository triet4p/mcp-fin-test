# Secret keys - Replace with your actual API keys
GOOGLE_API_KEY=your_google_api_key_here
#OPENAI_API_KEY=your_openai_api_key_here
#OPENROUTER_API_KEY=your_openrouter_api_key_here

# Providers - Choose between 'google', 'openai', 'openrouter' or 'ollama'
LLM_PROVIDER=google
# If use Ollama or Openrouter, please input BASE_URL to connect
#OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
#OLLAMA_BASE_URL=http://host.docker.internal:11434

# Chat models - Adjust based on your chosen provider
CHAT_MODEL=gemini-2.5-flash

# API Config
API_V1_BASE_ROUTE='/api/v1'

# Servers
MCP_SERVERS_REGISTRY_URL=http://mcp-servers:8000/api/v1

# Memory configuration - determines which memory backend to use. Use 'in-memory' or 'redis'
MEMORY_TYPE=in-memory
# If use redis, uncomment these lines
REDIS_HOST=mcp-fin-memory #if you up by docker-compose, use your service names
REDIS_PORT=6379
REDIS_DB=0

# Prompt Cache enabled, if you, change to 'true'
LLM_CACHE_ENABLED=false

# Langchain - Uncomment and set if you want to use LangSmith tracing
#LANGCHAIN_API_KEY=your_langchain_api_key_here
#LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
#LANGCHAIN_TRACING_V2=true
#LANGCHAIN_PROJECT=your_project_name
